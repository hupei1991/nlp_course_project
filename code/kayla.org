#+title: Word Tokenizer

#  :kayla: <2016-12-15 Thu>
 
#+begin_src python :session :output results
import pickle
from nltk import word_tokenize

segmented_sents = pickle.load( open( "../data/segmented/sent_list.p", "rb" ) )
word_tokenize = [(k,word_tokenize(v)) for (k,v) in segmented_sents]
pickle.dump(word_tokenize, open( "../data/tokenized/tokenize.p", "wb" ) )

#the code works at the python command line.
#
# kayla gregory, <2016-12-15 Thu>

#+end_src

#+results:


